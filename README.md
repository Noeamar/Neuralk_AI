# üß† TempTabFM ‚Äì Synthetic Time Series Tabular Data Generator  
_A temporal extension of the TabICL SCM designed for pre-training time series tabular foundation models._

---

## üìå 1. Project Overview

This repository implements a **Synthetic Time Series Tabular Data Generator**, inspired by the **Structural Causal Model (SCM)** from **TabICL**, but extended with:

‚úì **Temporal dependencies** (autoregressive memory ‚Üí `Œ±`)  
‚úì **Periodicity / seasonality** (`Œ≤`, lagged memory)  
‚úì **Gaussian noise** for dataset diversity  
‚úì **Hyperparameter sensitivity study**  
‚úì **Evaluation framework** for dataset-level quality & diversity  

This work is designed for a **TempTabFM** research context:  
> _‚ÄúHow do we generate enough high-quality temporal data to pre-train a foundation model for tabular time series?‚Äù_

---

## üìÅ 2. Repository Structure 


	‚Ä¢	prior/ ‚Äì utilities from TabICL (contains GaussianNoise, XSampler, etc.)
	‚Ä¢	TempMLP_SCM.py ‚Äì temporal SCM generator (MLP + AR + periodicity)
	‚Ä¢	metrics_uni.py ‚Äì evaluation of one dataset (ACF, ADF, CCF, spectrum)
	‚Ä¢	metrics.py ‚Äì evaluation of multiple datasets + diversity metrics
	‚Ä¢	SCM_temp_MLP.ipynb ‚Äì main notebook: generation + visualisation
	‚Ä¢	requirements.txt ‚Äì dependencies
	‚Ä¢	README.md ‚Äì project explanation

---

## 3. Installation

bash
python -m venv .venv_temp_scm
source .venv_temp_scm/bin/activate        # Linux/Mac
# or
.\.venv_temp_scm\Scripts\activate         # Windows

pip install --upgrade pip
pip install -r requirements.txt

---

## 4. Core Class ‚Äî TemporalMLPSCM

Located in: TempMLP_SCM.py

‚úî Autoregressive dependence: h_t = h_new + Œ± * h_{t‚àí1}
‚úî Periodicity: h_t += Œ≤ * h_{t‚àíperiod}
‚úî Gaussian noise: + Œµ
‚úî Block-wise dropout init ‚Üí increases structural diversity

from TempMLP_SCM import TemporalMLPSCM

model = TemporalMLPSCM(
    seq_len=100,
    num_features=10,
    num_causes=10,
    num_layers=4,
    hidden_dim=32,
    alpha=0.3,
    beta=1.2,
    period=20,
    use_periodicity=True,
    device="cpu",
)

X, y = model.forward()
print(X.shape)   # (100, 10)

X, y = model.generate_dataset(n_individuals=50)
print(X.shape)    # (50 * seq_len , num_features)

## 5. Temporal Evaluation (ONE dataset)

Located in metrics_uni.py

from metrics_uni import evaluate_dataset_temporality
evaluate_dataset_tempority(X)

## 6. Dataset-Level Diversity (MULTIPLE datasets)

Located in: metrics.py

from metrics import (
    dataset_signature, compute_correlation_signature,
    pairwise_distances, diversity_metrics,
    plot_all_diversity
)

X_list = []
for _ in range(10):
    X, y = model.generate_dataset(50)    # ‚ö† m√™mes hyperparams
    X_list.append(X)

# Extract signatures
sigs = [dataset_signature(X)["combined"] for X in X_list]
corr_sigs = [compute_correlation_signature(X) for X in X_list]

# Distance matrices
D_global = pairwise_distances(sigs)
D_corr = compute_pairwise_corr_distances(corr_sigs)

# Diversity indicators
print(diversity_metrics(D_global))
print(summarize_corr_diversity(D_corr))

# Plots
plot_all_diversity(D_global, D_corr)