# ğŸ§  TempTabFM â€“ Synthetic Time Series Tabular Data Generator  
_A temporal extension of the TabICL SCM designed for pre-training time series tabular foundation models._

---

## ğŸ“Œ 1. Project Overview

This repository implements a **Synthetic Time Series Tabular Data Generator**, inspired by the **Structural Causal Model (SCM)** from **TabICL**, but extended with:

âœ“ **Temporal dependencies** (autoregressive memory â†’ `Î±`)  
âœ“ **Periodicity / seasonality** (`Î²`, lagged memory)  
âœ“ **Gaussian noise** for dataset diversity  
âœ“ **Hyperparameter sensitivity study**  
âœ“ **Evaluation framework** for dataset-level quality & diversity  

This work is designed for a **TempTabFM** research context:  
> _â€œHow do we generate enough high-quality temporal data to pre-train a foundation model for tabular time series?â€_

---

## ğŸ“ 2. Repository Structure 

.
â”œâ”€â”€ prior/                      # Copied from TabICL (required)
â”‚   â”œâ”€â”€ utils/                 # GaussianNoise, XSampler
â”‚   â””â”€â”€ â€¦
â”œâ”€â”€ TempMLP_SCM.py             # Core temporal SCM generator
â”œâ”€â”€ metrics_uni.py             # Evaluate ONE dataset (temporal signal)
â”œâ”€â”€ metrics.py                 # Compare several datasets (diversity)
â”œâ”€â”€ SCM_temp_MLP.ipynb         # Full benchmark + visualisation
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## 3. Installation

bash
python -m venv .venv_temp_scm
source .venv_temp_scm/bin/activate        # Linux/Mac
# or
.\.venv_temp_scm\Scripts\activate         # Windows

pip install --upgrade pip
pip install -r requirements.txt

---

## 4. Core Class â€” TemporalMLPSCM

Located in: TempMLP_SCM.py

âœ” Autoregressive dependence: h_t = h_new + Î± * h_{tâˆ’1}
âœ” Periodicity: h_t += Î² * h_{tâˆ’period}
âœ” Gaussian noise: + Îµ
âœ” Block-wise dropout init â†’ increases structural diversity

from TempMLP_SCM import TemporalMLPSCM

model = TemporalMLPSCM(
    seq_len=100,
    num_features=10,
    num_causes=10,
    num_layers=4,
    hidden_dim=32,
    alpha=0.3,
    beta=1.2,
    period=20,
    use_periodicity=True,
    device="cpu",
)

X, y = model.forward()
print(X.shape)   # (100, 10)

X, y = model.generate_dataset(n_individuals=50)
print(X.shape)    # (50 * seq_len , num_features)

## 5. Temporal Evaluation (ONE dataset)

Located in metrics_uni.py

from metrics_uni import evaluate_dataset_temporality
evaluate_dataset_tempority(X)

## 6. Dataset-Level Diversity (MULTIPLE datasets)

Located in: metrics.py

from metrics import (
    dataset_signature, compute_correlation_signature,
    pairwise_distances, diversity_metrics,
    plot_all_diversity
)

X_list = []
for _ in range(10):
    X, y = model.generate_dataset(50)    # âš  mÃªmes hyperparams
    X_list.append(X)

# Extract signatures
sigs = [dataset_signature(X)["combined"] for X in X_list]
corr_sigs = [compute_correlation_signature(X) for X in X_list]

# Distance matrices
D_global = pairwise_distances(sigs)
D_corr = compute_pairwise_corr_distances(corr_sigs)

# Diversity indicators
print(diversity_metrics(D_global))
print(summarize_corr_diversity(D_corr))

# Plots
plot_all_diversity(D_global, D_corr)